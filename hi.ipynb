{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mukundan/projects/llm_app/supervisor_doctor_agent/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Milvus.\n",
      "Collection face_collection already exists.  Loading...\n",
      "Connected to PostgreSQL\n",
      "Tables created successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage\n",
    "from agents.general_agent import create_general_agent\n",
    "from agents.specialized_agent import create_specialized_agent\n",
    "from database.postgres_db import store_chat_history\n",
    "from langgraph_app.graph_state import GraphState\n",
    "from langgraph_app.supervisor import supervisor_node\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI # Import the Gemini model\n",
    "from langgraph_app.tools import route_to_specialist\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_message(state: GraphState):\n",
    "    \"\"\"Records messages to the database.\"\"\"\n",
    "    patient_id = state['patient_id']\n",
    "    for message in state['messages']:\n",
    "        store_chat_history(patient_id, message.content, message.role)\n",
    "    return state\n",
    "\n",
    "def initialize_conversation(state: GraphState):\n",
    "    \"\"\"Logs the initial patient message into chat history\"\"\"\n",
    "    patient_id = state['patient_id']\n",
    "    for message in state['messages']:\n",
    "        store_chat_history(patient_id, message.content, 'user')\n",
    "    return state\n",
    "\n",
    "def general_agent_node(state: GraphState):\n",
    "    \"\"\"General agent node that routes to other specialists\"\"\"\n",
    "    tools = [route_to_specialist] #Define the tools inside\n",
    "    general_agent = create_general_agent(tools)\n",
    "    input_message = state['messages'][-1].content\n",
    "\n",
    "    result = general_agent.invoke({\"input\": input_message, \"chat_history\": state[\"messages\"],\"messages\":state['messages']}) # No Messages are needed\n",
    "    \n",
    "    #Check the tool section of the output\n",
    "    specialization = None\n",
    "    if \"Routing to\" in result[\"output\"] and \"FINISH\" not in result[\"output\"]: #Force check\n",
    "        specialization = result[\"output\"].split(\"Routing to \")[1].split(\" because\")[0] #This is because the `general_agent` has a \"routing tool\"\n",
    "    elif \"FINISH\" in result[\"output\"]:\n",
    "        specialization = \"end\" #Force the agent to \"end\" for edge cases\n",
    "    else:\n",
    "        specialization = None #If for some reason, the tool is not in result but no FINISH is detected, there is nothing for the tool to act, hence \"None\".\n",
    "\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"output\"], name=\"general_agent\")],\n",
    "        \"specialization\": specialization #Always none here. The tool determines the specialisation based on the response of the Agent\n",
    "    }\n",
    "\n",
    "def specialized_agent_node(state: GraphState):\n",
    "    \"\"\"Specialized agent node that performs RAG\"\"\"\n",
    "    specialization = state['specialization']\n",
    "    input_message = state['messages'][-1].content\n",
    "\n",
    "    if specialization:\n",
    "        specialized_agent = create_specialized_agent(specialization)\n",
    "        response = specialized_agent.invoke({\"input\": input_message})\n",
    "        return {\"messages\": [HumanMessage(content=response, name=\"specialized_agent\")], \"specialization\": None} #Always set this back to none\n",
    "    else:\n",
    "        return {\"messages\": [HumanMessage(content=\"Error: No specialization specified.\", name = \"specialized_agent\")], \"specialization\": None} #Return None too\n",
    "\n",
    "def end_node(state):\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LangGraph\n",
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tinitialize_conversation(initialize_conversation)\n",
      "\tgeneral_agent(general_agent)\n",
      "\tspecialized_agent(specialized_agent)\n",
      "\trecord_message(record_message)\n",
      "\tsupervisor(supervisor)\n",
      "\tend(end)\n",
      "\t__end__(<p>__end__</p>)\n",
      "\t__start__ --> initialize_conversation;\n",
      "\tgeneral_agent --> supervisor;\n",
      "\tinitialize_conversation --> general_agent;\n",
      "\trecord_message --> end;\n",
      "\trecord_message --> supervisor;\n",
      "\tspecialized_agent --> supervisor;\n",
      "\tsupervisor -.-> general_agent;\n",
      "\tsupervisor -.-> specialized_agent;\n",
      "\tsupervisor -.-> end;\n",
      "\tsupervisor -.-> general_agent;\n",
      "\tsupervisor -.-> specialized_agent;\n",
      "\tsupervisor -.-> record_message;\n",
      "\tsupervisor -.-> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Creates the LangGraph graph using supervisor agent.\"\"\"\n",
    "print(\"Creating LangGraph\")\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "#Nodes\n",
    "builder.add_node(\"initialize_conversation\", initialize_conversation)\n",
    "builder.add_node(\"general_agent\", general_agent_node)\n",
    "builder.add_node(\"specialized_agent\", specialized_agent_node)\n",
    "builder.add_node(\"record_message\", record_message)\n",
    "builder.add_node(\"supervisor\", supervisor_node) #Supervisor\n",
    "builder.add_node(\"end\", end_node) #Fix the node by passing function\n",
    "\n",
    "#Edges\n",
    "builder.set_entry_point(\"initialize_conversation\")\n",
    "\n",
    "#Initial\n",
    "builder.add_edge(\"initialize_conversation\", \"general_agent\")\n",
    "\n",
    "#Add supervisor\n",
    "builder.add_edge(\"general_agent\", \"supervisor\")\n",
    "builder.add_edge(\"specialized_agent\", \"supervisor\")\n",
    "\n",
    "#Add record_message to the flow before supervisor node - NEW ADDITION TO ADDRESS RECURSION ERROR\n",
    "builder.add_edge(\"record_message\", \"supervisor\") #Point the record message to the supervisor\n",
    "\n",
    "# Routing to specialized agents\n",
    "CONDITIONAL_MAP = {\n",
    "    \"general_agent\": \"general_agent\",\n",
    "    \"specialized_agent\": \"specialized_agent\",\n",
    "    \"end\": \"end\", #Make it default to end\n",
    "}\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda state: state[\"specialization\"] if state[\"specialization\"] != None and state[\"specialization\"] != \"end\" else \"end\",\n",
    "    CONDITIONAL_MAP\n",
    ")\n",
    "\n",
    "builder.add_edge(\"record_message\", \"end\") #Fix the final edge\n",
    "\n",
    "graph = builder.compile()\n",
    "print(graph.get_graph().draw_mermaid())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
